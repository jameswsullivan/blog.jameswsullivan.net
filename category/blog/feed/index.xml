<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>blog &#8211; howdy</title>
	<atom:link href="/category/blog/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description></description>
	<lastBuildDate>Tue, 11 Apr 2023 01:24:00 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.2</generator>
	<item>
		<title>Self-hosted Nextcloud with Docker</title>
		<link>/self-hosted-nextcloud-with-docker/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Tue, 11 Apr 2023 01:24:00 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Nextcloud]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Web Hosting]]></category>
		<guid isPermaLink="false">/?p=2303</guid>

					<description><![CDATA[Spin up self-hosted Nextcloud with MySQL using Docker.]]></description>
										<content:encoded><![CDATA[
<p>My <a href="/self-host-nextcloud/">previous attempt</a> to spin up a self-hosted Nextcloud was directly on a Ubuntu VM, but its virtual disks were not configured in a way that&#8217;s easily expandable as data grows. This time I&#8217;m using Docker and have addressed the issues.</p>



<h2 class="wp-block-heading">Components:</h2>



<ul>
<li>The Docker host is a dedicated Hyper-V VM running Ubuntu Server in Windows Server 2022.</li>



<li><a href="https://hub.docker.com/_/nextcloud" target="_blank" rel="noreferrer noopener">Nextcloud</a> Docker image.</li>



<li><a href="https://hub.docker.com/r/ubuntu/mysql" target="_blank" rel="noreferrer noopener">Ubuntu/MySQL</a> Docker image.</li>



<li>A storage pool consisting of 6 x 500GB 2.5&#8221; HDDs and a virtual disk in Parity mode with 2 disks set as redundant, bringing total capacity to 1.35TB. This virtual disk will be mounted to Nextcloud&#8217;s <code>/var/www/html</code> path to store persistent data.</li>



<li>An 100GB virtual disk for MySQL persistent data (<code>/var/lib/mysql</code>).</li>
</ul>



<h2 class="wp-block-heading">Nextcloud Dockerfile:</h2>



<pre class="wp-block-code"><code>FROM nextcloud

# Configure PHP parameters via environment variables.
ENV PHP_MEMORY_LIMIT=4096M
ENV PHP_UPLOAD_LIMIT=4096M

# Install packages and configure timezone.
RUN apt-get update -y &amp;&amp; \
    apt-get upgrade -y &amp;&amp; \
    apt-get install nano -y &amp;&amp; \
    apt-get install tzdata -y &amp;&amp; \
    ln -fs /usr/share/zoneinfo/US/Central /etc/localtime &amp;&amp; \
    dpkg-reconfigure -f noninteractive tzdata

EXPOSE 80 443</code></pre>



<h2 class="wp-block-heading">Containers:</h2>



<pre class="wp-block-code"><code># Build Nextcloud image
docker image build --tag nextcloud:1.0 --progress plain --no-cache . 2>&amp;1 | tee build.log

# Start Nextcloud container.
# The drive for Nextcloud's persistent data is mounted to /mnt/nextcloud_data .
docker run -dit --name MY-NEXTCLOUD-CONTAINER --ip IP-ADDRESS --network DOCKER-NETWORK --restart=unless-stopped --hostname=MY_NEXTCLOUD_CONTAINER_HOSTNAME -v /mnt/nextcloud_data:/var/www/html nextcloud:1.0

# Start a MySQL container for Nextcloud.
# The virtual disk for MySQL's persistent data is mounted to /mnt/nextcloud_db .
docker run -dit --name MY-NEXTCLOUD-DB-CONTAINER --ip IP-ADDRESS --network DOCKER-NETWORK --hostname=MY_NEXTCLOUD_DB_CONTAINER_HOSTNAME --restart=unless-stopped -v /mnt/nextcloud_db:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=MY-ROOT-PASSWORD ubuntu/mysql</code></pre>



<h2 class="wp-block-heading">Docker compose:</h2>



<p>To be added.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Invalid Time error and Unable to Change Time Zone</title>
		<link>/invalid-time-error-and-unable-to-change-time-zone/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Sun, 26 Mar 2023 16:52:31 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[System Administration]]></category>
		<category><![CDATA[Windows Systems Administration]]></category>
		<guid isPermaLink="false">/?p=2217</guid>

					<description><![CDATA[Fix the Invalid Time error and the Time Zone setting greyed out issue on Windows.]]></description>
										<content:encoded><![CDATA[
<p>If your applications are encountering an Invalid Time error, check the following settings:</p>



<pre class="wp-block-preformatted">Control Panel - Date and Time - Internet Time - Change Settings ... - Synchronize with an Internet time server - Set server to: time.nist.gov</pre>



<p>For some reason the <code>time.windows.com</code> occasionally has issues with certain programs.</p>



<p>If your <code>Time zone</code> setting is greyed out in Windows Settings, use <a href="https://learn.microsoft.com/en-us/troubleshoot/windows-client/shell-experience/cannot-set-timezone-automatically">this guide</a> to fix it:</p>



<pre class="wp-block-code"><code>1. Change the Set time zone automatically setting and set the data value of the registry entry
HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\tzautoupdate\Start
as follows:

3	Enable Set time zone automatically
4	Disable Set time zone automatically

2. Change the location setting and set the value of the registry entry
HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\CapabilityAccessManager\ConsentStore\location\Value
as follows:

Allow	On
Deny	Off</code></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Troubleshooting Apache Web Server and Name-based Virtual Hosting</title>
		<link>/troubleshooting-apache-web-server-and-name-based-virtual-hosting/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Sat, 25 Mar 2023 23:26:42 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Apache]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<category><![CDATA[Web Hosting]]></category>
		<guid isPermaLink="false">/?p=2185</guid>

					<description><![CDATA[This troubleshooting note wraps up the Name-based Virtual Hosting Series.]]></description>
										<content:encoded><![CDATA[
<p>During the process of setting up name-based virtual hosting with Apache, I ran into a few issues with the WordPress container, this post documents the steps taken to address them.</p>



<h2 class="wp-block-heading">Background:</h2>



<p>I use the locally hosted WordPress site to write documentation and blog posts and then use Simply Static to convert and get it ready for GitHub Pages. During the process I ran into the following issues:</p>



<ul>
<li>WordPress Site Health check has three critical issues:
<ul>
<li>The required module, gd, is not installed, or has been disabled.</li>



<li>The REST API encountered an error.</li>



<li>Your site could not complete a loopback request.</li>
</ul>
</li>



<li><em>Updating failed. The response is not a valid JSON response.</em> when creating and updating posts.</li>



<li>Simply Static&#8217;s failed diagnostics:
<ul>
<li>Checking if WordPress can make requests to itself from YOUR_IP  FAIL</li>



<li>Checking for cURL support  FAIL</li>
</ul>
</li>
</ul>



<h2 class="wp-block-heading">Issue 1: Updating failed. The response is not a valid JSON response.</h2>



<p>I get this error only after I&#8217;ve set the <strong>Permalinks</strong> setting to anything else other than the default <strong>Plain</strong> setting. When <strong>Permalinks</strong> is not set to <strong>Plain</strong>, the URLs need to be rewritten, and that&#8217;s when this error will occur. In my case, it turned out to be that I forgot to add the &lt;Directory> tag in the virtual host configuration file. As you can see in <a href="/configure-apache-web-server-and-name-based-virtual-hosting-with-ubuntu/">this post</a>, my configuration file looks like this:</p>



<pre class="wp-block-code"><code>&lt;VirtualHost *:80>
    ServerAdmin webmaster@example1.mydomain
    ServerName example1.mydomain
    DocumentRoot /var/www/html/example1.mydomain
    DirectoryIndex index.php
    ErrorLog ${APACHE_LOG_DIR}/example1.mydomain_error.log
    CustomLog ${APACHE_LOG_DIR}/example1.mydomain_access.log combined
&lt;/VirtualHost></code></pre>



<p>But the correct configs for rewrite to work need to look like this:</p>



<pre class="wp-block-code"><code>&lt;VirtualHost *:80>
    ServerAdmin webmaster@example1.mydomain
    ServerName example1.mydomain
    DocumentRoot /var/www/html/example1.mydomain

        &lt;Directory /var/www/html/example1.mydomain>
                Options Indexes FollowSymLinks
                AllowOverride All
                Require all granted
                DirectoryIndex index.php
        &lt;/Directory>

    ErrorLog ${APACHE_LOG_DIR}/example1.mydomain_error.log
    CustomLog ${APACHE_LOG_DIR}/example1.mydomain_access.log combined
&lt;/VirtualHost></code></pre>



<p>Without the <strong>&lt;Directory></strong> element, the <strong>.htaccess</strong> file is unable to override the rewrite rules.</p>



<h2 class="wp-block-heading">Issue 2: WordPress Site Health Critical Issues</h2>



<p><strong>The required module, gd, is not installed, or has been disabled.</strong></p>



<pre class="wp-block-code"><code># Install the php8.1-gd module
apt-get install php8.1-gd -y</code></pre>



<p><strong>The REST API encountered an error.</strong></p>



<pre class="wp-block-code"><code>The REST API is one way that WordPress and other applications communicate with the server. For example, the block editor screen relies on the REST API to display and save your posts and pages.

When testing the REST API, an error was encountered:

REST API Endpoint: http://example1.mydomain/wp-json/wp/v2/types/post?context=edit
REST API Response: (http_request_failed) cURL error 6: Could not resolve host: example1.mydomain</code></pre>



<p><strong>Your site could not complete a loopback request.</strong></p>



<pre class="wp-block-code"><code>Loopback requests are used to run scheduled events, and are also used by the built-in editors for themes and plugins to verify code stability.

The loopback request to your site failed, this means features relying on them are not currently working as expected.
Error: cURL error 6: Could not resolve host: example1.mydomain (http_request_failed)</code></pre>



<p>Edit the <strong>/etc/hosts</strong> file:</p>



<pre class="wp-block-code"><code>nano /etc/hosts

# Add a new line: IP hostname. e.g. 192.168.0.4 website1.example.com</code></pre>



<p>Additionally, you might need to install the curl package:</p>



<pre class="wp-block-code"><code>apt-get install php8.1-curl -y

# Verify curl version:
curl --version

# Verify curl is enabled in php.ini
nano /etc/php/8.1/apache2/php.ini

# Uncomment this line:
extension=curl</code></pre>



<p>Adding this entry in <strong>/etc/hosts</strong> file also resolves Simply Static&#8217;s <em>&#8220;Checking if WordPress can make requests to itself from your_IP&#8221;</em> FAIL issue.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Configure Apache Web Server and Name-based Virtual Hosting with Ubuntu</title>
		<link>/configure-apache-web-server-and-name-based-virtual-hosting-with-ubuntu/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Fri, 03 Feb 2023 20:19:00 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Apache]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">/?p=18</guid>

					<description><![CDATA[This is the fourth installment of the Name-based Virtual Hosting Series.]]></description>
										<content:encoded><![CDATA[
<p>This is the final installment of my dev environment setup which documents the process of setting up Apache web server and name-based virtual hosting. My setup has CIFS/Samba volume <em>my_smb_vol</em> and an ipvlan network <em>docker_dev_net</em>.</p>



<h2 class="wp-block-heading">Spin up a Ubuntu Docker container:</h2>



<pre class="wp-block-code"><code>docker run -dit --name WEB_SERVER --network docker_dev_net --ip 192.168.1.103 --mount source=my_smb_vol,destination=/SharedVolume ubuntu

# -p 443:443 -p 80:80 -p 22:22
# Port exposure is optional because the containers will be part of the same network that my other machines are in.</code></pre>



<p>Install necessary packages:</p>



<pre class="wp-block-code"><code># Install network utilities for troubleshooting:
apt-get install iputils-ping -y
apt-get install iproute2 -y
apt-get install traceroute -y

# Install SSH:
apt-get install openssh-client -y
apt-get install openssh-server -y

# Install sudo and other utilities:
apt-get install sudo -y
apt-get install nano -y

# Install apache, php, and php-mysql:
apt-get install apache2 -y
apt-get install php8.1 -y
apt-get install php-mysql -y
apt-get install libapache2-mod-php -y</code></pre>



<p>Verify services are running and start the them if not:</p>



<pre class="wp-block-code"><code># ssh and apache2 service status
service ssh status
service apache2 status

# start the services:
service ssh start
service apache2 start</code></pre>



<p>Hostname and name server (optional):</p>



<pre class="wp-block-code"><code># Depending on your setup, you might need to specify the --hostname when creating your container:

--hostname=your_hostname

# Technically after specifying --ip and --hostname , you shouldn't need to edit /etc/resolv.conf anymore. To verify:

cat /etc/resolv.conf</code></pre>



<p>Verify php version:</p>



<pre class="wp-block-code"><code># Create a info.php file under the /var/www/html directory with the following content:

&lt;?php phpinfo();?&gt;</code></pre>



<p>Now that you should be able to visit the Apache server&#8217;s default landing page and the info.php page to verify that the Apache server is running and view your php version.</p>



<h2 class="wp-block-heading">Set up name-based virtual hosting:</h2>



<pre class="wp-block-code"><code># The example websites I'm using are: example.mydomain, example1.mydomain, example2.mydomain.

# Create directories:
# example.mydomain will reside under /var/www/html as the "main" website.

mkdir /var/www/html/example1.mydomain
mkdir /var/www/html/example2.mydomain

# Change ownership of the directories. I simply changed the entire html directory and its subdirectories' ownership to www-data for my convenience.

chown -R www-data:www-data /var/www/html

# Create Virtual Host configuration files for your sites.
touch /etc/apache2/sites-available/example.mydomain.conf
touch /etc/apache2/sites-available/example1.mydomain.conf
touch /etc/apache2/sites-available/example2.mydomain.conf

# Use nano to add the corresponding content to your site config files. Edit the ServerName and DocumentRoot as needed to point to the your domains and directories:

# example.mydomain.conf or use the 000-default.conf:
&lt;VirtualHost *:80&gt;
    ServerAdmin webmaster@example.mydomain
    ServerName example.mydomain
    DocumentRoot /var/www/html
    DirectoryIndex index.html
    ErrorLog ${APACHE_LOG_DIR}/example.mydomain_error.log
    CustomLog ${APACHE_LOG_DIR}/example.mydomain_access.log combined
&lt;/VirtualHost&gt;

# example1.mydomain.conf:
&lt;VirtualHost *:80&gt;
    ServerAdmin webmaster@example1.mydomain
    ServerName example1.mydomain
    DocumentRoot /var/www/html/example1.mydomain
    DirectoryIndex index.php
    ErrorLog ${APACHE_LOG_DIR}/example1.mydomain_error.log
    CustomLog ${APACHE_LOG_DIR}/example1.mydomain_access.log combined
&lt;/VirtualHost&gt;

# Enable the configuration files for the sites:
a2ensite example1.mydomain
a2ensite example2.mydomain

# Restart apache2 service and verify that apache2 is running:
service apache2 reload
service apache2 status

# Of course, you will need to add your own index.html or index.php files under the sites' directories.</code></pre>



<p>Configure your router or DNS server records:</p>



<pre class="wp-block-code"><code># I'm using my Cisco router as an example:

ip host example.mydomain 192.168.1.103
ip host example1.mydomain 192.168.1.103
ip host example2.mydomain 192.168.1.103</code></pre>



<p>Now that you should be able to visit the sites by going to:</p>



<pre class="wp-block-code"><code>http:&#47;&#47;example.mydomain
http://example1.mydomain/
http://example2.mydomain/</code></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Configure Docker MySQL Server</title>
		<link>/configure-docker-mysql-server/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Fri, 03 Feb 2023 17:14:00 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Apache]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[MySQL]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=2124</guid>

					<description><![CDATA[This is the third installment of the Name-based Virtual Hosting Series.]]></description>
										<content:encoded><![CDATA[
<p>Background:</p>



<p>I set up this MySQL server using the <strong><a rel="noreferrer noopener" href="https://hub.docker.com/r/ubuntu/mysql" target="_blank">ubuntu/mysql</a></strong> Docker image and it&#8217;s part of my dev environment setup. My setup has <a href="/docker-volumes-and-smb-share/">CIFS/Samba volume</a> <em>my_smb_vol</em> and an <a href="/ubuntu-server-docker-host-and-docker-networking/">ipvlan network</a> <em>docker_dev_net</em>.</p>



<p>Steps:</p>



<p>Create a ubuntu/mysql container:</p>



<pre class="wp-block-code"><code>docker run -dit --name MySQL_DEV --network docker_dev_net --ip 192.168.1.101 --mount source=my_smb_vol,destination=/SharedVolume -p 3306:3306 -p 22:22 -e MYSQL_ROOT_PASSWORD=password ubuntu/mysql</code></pre>



<p>Create users and databases:</p>



<pre class="wp-block-code"><code># Connect to mysql instance:
mysql -u root -p

# Show databases:
SHOW DATABASES;

# Describe a table:
USE mysql;
DESC user;

# Show all the users:
SELECT user, host FROM mysql.user;

# Create databases:
CREATE DATABASE my_wordpress_db;

# Create users:
CREATE USER 'wordpress_user'@'192.168.1.103' IDENTIFIED BY 'password';

# Explanation here: 192.168.1.103 is my other Ubuntu Apache web server container. If you are creating a local user use the following command:
CREATE USER 'wordpress_user'@'localhost' IDENTIFIED BY 'password';

# Grant privileges to the user:
GRANT ALL ON my_wordpress_db.* TO 'wordpress_user'@'192.168.1.103' WITH GRANT OPTION;
FLUSH PRIVILEGES;

# Verify privileges:
SHOW GRANTS FOR 'wordpress_user'@'192.168.1.103';</code></pre>



<p>Allow remote connection to this mysql instance:</p>



<pre class="wp-block-code"><code># You will have to modify one of the .cnf files to allow remote connection to your mysql instance, if you list the files under /etc/mysql/, you'll find the following files and directories listed:

ls -al /etc/mysql/

conf.d
my.cnf
my.cnf.fallback

# See the content of my.cnf:
cat /etc/mysql/my.cnf

# On the last two lines of the output, you should see:
# Custom config should go here
!includedir /etc/mysql/conf.d/

# List files under the conf.d directory:
ls -al /etc/mysql/conf.d/

docker.cnf
mysql.cnf
mysqldump.cnf

# The mysql.cnf is what you're going to edit:
nano /etc/mysql/conf.d/mysql.cnf

# By default, your mysql.cnf file should only contain one line: &#91;mysql]. Add a new line below it so it looks like the following:

&#91;mysql]
bind-address = 0.0.0.0</code></pre>



<p>Test connection to the mysql instance from the remote machine/container using the newly created <em>wordpress_user</em> user.</p>



<pre class="wp-block-code"><code># I'm performing these steps on the Ubuntu Apache web server, 192.168.1.103:
# Install the mysql-client package if it's not been installed.

apt-get install mysql-client

# Connect to the mysql instance at 192.168.1.101:
mysql -h 192.168.1.101 -u wordpress_user -p</code></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Docker volumes and SMB share</title>
		<link>/docker-volumes-and-smb-share/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Fri, 03 Feb 2023 16:52:00 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=2122</guid>

					<description><![CDATA[This is the second installment of the Name-based Virtual Hosting Series.]]></description>
										<content:encoded><![CDATA[
<p>I&#8217;m recently setting up a dev environment with different Docker containers running Ubuntu and database services and there are certain things I need them to persist and be shared between the containers, the host, and my other computers (mostly Windows) on the network. Since my home lab setup is a Windows house, SMB shares seem to be the most convenient solution.</p>



<p>Create a <a href="https://docs.docker.com/storage/volumes/#create-cifssamba-volumes" target="_blank" rel="noreferrer noopener">Docker CIFS/Samba volume</a>:</p>



<pre class="wp-block-code"><code># Of course, you need to create a network share first, mine is: \\main_server\DockerShare, and have a user &amp; password ready to access the share.

docker volume create --driver local --opt type=cifs --opt device=//main_server/DockerShare --opt o=addr=main_server,username=your_username,password=your_password,file_mode=0777,dir_mode=0777 --name my_smb_vol</code></pre>



<p>After the volume is created, you can start a container and mount the volume to it:</p>



<pre class="wp-block-code"><code># List all volumes

docker volume ls

# Start the WEB_SERVER container with the volume just created

docker run -dit --name WEB_SERVER --network docker_dev_net --ip 192.168.1.103 --mount source=my_smb_vol,destination=/SharedVolume -p 443:443 -p 80:80 -p 22:22 ubuntu</code></pre>



<p></p>



<p></p>



<p></p>



<p></p>



<p></p>



<p></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Ubuntu Server Docker Host and Docker Networking</title>
		<link>/ubuntu-server-docker-host-and-docker-networking/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Fri, 03 Feb 2023 04:19:00 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Apache]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Web Hosting]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=2115</guid>

					<description><![CDATA[This is the first installment of the Name-based Virtual Hosting Series.]]></description>
										<content:encoded><![CDATA[
<p>Since I started with my new job late last year I have been dealing quite bit with Docker, the majority of the applications at work are hosted and developed in a Docker environment, and even for personal projects Docker has made hosting and development much easier compared to using traditional VMs. But recently I came across a rather inconvenient issue with Docker Desktop for Windows when it comes to networking.</p>



<p>The background is that my home lab&#8217;s network is well organized and controlled by IPs, access-lists, etc., via Cisco switches and routers, I needed my Docker host and dev containers to have static IP addresses and be within a specific IP range and add custom DNS records to my router to point to them. The Docker networking part is fairly straightforward, but what&#8217;s inconvenient is how Docker Desktop for Windows and WSL2 handle their networking part behind the scene. WSL2 gets its own vEthernet adapter with an IP in the 172.0.0.0 range and the containers get placed in a different 172.0.0.0 network segment and assigned with dynamic IPs and depending on how the Hyper-V and WSL2 backend handles the routing and switching, it&#8217;s rather difficult (if not impossible) to easily assign static IPs to the containers within the same IP segment as the host machine and make them part of the same subnet for easy access. After a couple of hours fiddling around with different solutions I basically gave up on it as it&#8217;s really not worth the time and efforts doing so, I opted to have a dedicated Hyper-V VM running Ubuntu Server as the Docker host on my home server.</p>



<p>Since it&#8217;s Ubuntu Server, the networking part becomes very straightforward:</p>



<p>The Docker host VM has its own static IP, e.g. 192.168.1.100/24. (The IP is assigned to interface <strong>eth0</strong> in Ubuntu.)</p>



<pre class="wp-block-code"><code>ip address show eth0</code></pre>



<p>Create an <strong><a href="https://docs.docker.com/network/ipvlan/" target="_blank" rel="noreferrer noopener">ipvlan</a></strong> network of the same subnet:</p>



<pre class="wp-block-code"><code>docker network create --driver ipvlan --subnet=192.168.1.0/24 --gateway=192.168.1.1 -o ipvlan_mode=l2 -o parent=eth0 docker_dev_net</code></pre>



<p>And then we can create containers using this network and assign static IPs to them:</p>



<pre class="wp-block-code"><code># I'm using the ubuntu/mysql Docker Image here as an example.
# The port 22 here is for being able to SSH into this container from my main windows computer.

docker run -dit --name MySQL_DEV --network docker_dev_net --ip 192.168.1.101 -p 3306:3306 -p 22:22 -e MYSQL_ROOT_PASSWORD=password ubuntu/mysql

# Make sure you add the corresponding DNS entries to your DNS server or router. e.g., on my Cisco router:

ip host MySQL_DEV.mydomain 192.168.1.101</code></pre>



<p>After the containers are running, test the connection with PowerShell:</p>



<pre class="wp-block-code"><code>Test-NetConnection -ComputerName MySQL_DEV.mydomain -Port 3306</code></pre>



<p>To conclude, it&#8217;s much easier to create Docker networks and containers and tap them into your existing network infrastructure in this way, without having to mess with Docker Desktop for Windows and WSL2. The final results are that I started three containers running MySQL, PostgreSQL, and Ubuntu, respectively. (The Ubuntu container will serve as an Apache web server hosting my websites.)</p>



<pre class="wp-block-code"><code>docker run -dit --name WEB_SERVER --network docker_dev_net --ip 192.168.1.103 -p 443:443 -p 80:80 -p 22:22 ubuntu

docker run -dit --name MySQL_DEV --network docker_dev_net --ip 192.168.1.101 -p 3306:3306 -p 22:22 -e MYSQL_ROOT_PASSWORD=password ubuntu/mysql

docker run -dit --name PostgreSQL_DEV --network docker_dev_net --ip 192.168.1.102 -p 5432:5432 -p 22:22 -e POSTGRES_PASSWORD=password postgres</code></pre>



<p></p>



<p></p>



<p></p>



<p></p>



<p></p>



<p></p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Repair Corrupt System Files in Windows 10</title>
		<link>/corrupt-windows-10-system-files-repair/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Mon, 21 Mar 2022 02:24:48 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[System Administration]]></category>
		<category><![CDATA[Windows Systems Administration]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=2023</guid>

					<description><![CDATA[Repair Windows Explorer crash with SFC /SCANNOW and DISM after Windows Update's reboot caused system file damage.]]></description>
										<content:encoded><![CDATA[
<p>The initial file corruption seems to have happened after an automated reboot by Windows Update while some disc scanning operations were still ongoing. The sudden reboot probably damaged some system files that rendered Windows Explorer to crash immediately after opening, and Windows Explorer would also crash immediate when your right click on any drives as well as on the recycle bin.</p>



<p>The repair process was fairly straightforward using <code>SFC</code> and <code>DISM</code>. However, <code>SFC /SCANNOW</code> was not able to perform the repair at first and gave the <code>Windows Resource Protection could not perform the requested operation.</code> message. This usually points to corrupt files that would require a disk scan. <code>CHKDSK C: /R</code> was issued and system drive was checked and repaired upon next reboot.</p>



<p>After <code>CHKDSK</code> finished and all disk errors were repaired, <code>SFC /SCANNOW</code> was still not successful due to some files&#8217; <code>hash mismatch</code> (logs can be checked under <code>WINDIR\LOGS\CBS\CBS.log</code>), so I resorted to using <code>DISM /Online /Cleanup-Image /RestoreHealth</code> . However, after issuing this command, it was still unable to perform the repair with another error message <code>The source files could not be found</code>. This means that you&#8217;ll need a healthy Windows installation ISO file to be the source file, usually you can use the <code>Windows Media Creation Tool</code> to create an installation media, but when I performed the repair in <code>Safe Mode</code> , the Media Creation Tool was failing with the error code <strong>0x8007043C &#8211; 0x90018</strong> every time it ran. Eventually I used <a href="https://tb.rg-adguard.net/public.php"><strong>this</strong></a> link to manually download a Windows 10 ISO file. When the ISO file is ready, extract the content into a folder and check under the &#8220;sources&#8221; directory to see whether you have the file <code>install.wim</code> or <code>install.esd</code>, as the following commands will be slight different.</p>



<pre class="wp-block-code"><code>* Assume my extracted installation files are under E:\Win10\sources\install.wim

DISM /Online /Cleanup-Image /RestoreHealth /Source:wim:E:\Win10\sources\install.wim:6 /LimitAccess

* Use this command instead if your image contains install.esd file

DISM /Online /Cleanup-Image /RestoreHealth /Source:ESD:E:\Win10\sources\install.ESD:6 /LimitAccess
 
* This command eventually did the trick for me and successfully finished the repair. If you need to find out the index number (the index number might be different if you're using a different installation image), the following command can help identify, and then just replace the number 6 in the commands above with the right Windows version of your own.

DISM /get-wiminfo /wimfile:E:\Win10\sources\install.wim</code></pre>



<p>For more comprehensive instructions, refer to <a href="https://www.windowscentral.com/how-use-dism-command-line-utility-repair-windows-10-image">this</a> article.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Set up Docker on Ubuntu Server</title>
		<link>/set-up-docker-on-ubuntu-server/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Tue, 21 Sep 2021 06:14:07 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[Standard Notes]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=1638</guid>

					<description><![CDATA[Setting up Ubuntu Server, SSH, UFW, Nginx, and Docker.]]></description>
										<content:encoded><![CDATA[
<h2 class="wp-block-heading">Environment: Windows Server 2019, Hyper-V, Ubuntu Server 20.04.3 LTS.</h2>



<p>1. After Ubuntu Server is installed on a VM (with a clean and minimum installation without any preloaded packages), set up Docker and OpenSSH.</p>



<pre class="wp-block-code"><code># Install OpenSSH
apt upgrade
apt update
apt install openssh-server

# Check SSH Status
systemctl status ssh

# Allow ssh over UFW firewall
ufw allow ssh</code></pre>



<p>2. Enable UFW, check status, and configure rules.</p>



<pre class="wp-block-code"><code># Enable UFW
ufw enable

# Check status and rules
ufw status

# Check status and make results numbered
ufw status numbered

# Disable UFW
ufw disable

# Block IP
ufw deny from IP-Address

# Block by subnet
ufw deny from IP/CIDR

# Block connections on interface
ufw deny in on eth0 from IP-Address

# Allow commands:
ufw allow from IP-Address
ufw allow in on eth0 from IP-Address

# Delete rule
ufw status numbered
ufw delete &#91;number]

# Allow by protocol
ufw allow from IP-Address proto tcp to any port 22
ufw allow from IP/CIDR proto tcp to any port 22
ufw allow proto tcp from any to any port 80,443</code></pre>



<p>3. Disable ipv6 on Ubuntu Server.</p>



<pre class="wp-block-code"><code># Add
net.ipv6.conf.all.disable_ipv6=1
net.ipv6.conf.default.disable_ipv6=1
net.ipv6.conf.lo.disable_ipv6=1
# to file /etc/sysctl.conf</code></pre>



<p>4. Reduce Ubuntu shutdown time.</p>



<pre class="wp-block-code"><code># Edit /etc/systemd/system.conf and uncomment DefaultTimeoutStopSec=90s and set it to a desired value

DefaultTimeoutStopSec=15s</code></pre>



<p>5. Install Docker</p>



<pre class="wp-block-code"><code># Remove existing Docker installations, if any
apt remove docker docker-engine docker.io containerd runc

# Install using the repository
apt update
apt install apt-transport-https ca-certificates curl gnupg lsb-release

# Add Docker's official GPG key
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Set up stable repository
echo \
"deb &#91;arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable" \
| sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Install Docker engine
apt update
apt install docker-ce docker-ce-cli containerd.io

# Verify that Docker Engine is correctly installed
docker version</code></pre>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Self-signed SSL Certificate, Apache, and Nextcloud</title>
		<link>/self-signed-ssl-certificate-apache-and-nextcloud/</link>
		
		<dc:creator><![CDATA[James]]></dc:creator>
		<pubDate>Sun, 19 Sep 2021 20:58:07 +0000</pubDate>
				<category><![CDATA[blog]]></category>
		<category><![CDATA[Apache]]></category>
		<category><![CDATA[Docker]]></category>
		<category><![CDATA[Hosting]]></category>
		<category><![CDATA[Linux]]></category>
		<category><![CDATA[Nextcloud]]></category>
		<category><![CDATA[Self-Hosting]]></category>
		<category><![CDATA[SSL]]></category>
		<category><![CDATA[Ubuntu]]></category>
		<guid isPermaLink="false">https://www.alexchen.net/?p=1622</guid>

					<description><![CDATA[Perfecting SSL configuration on Nextcloud server.]]></description>
										<content:encoded><![CDATA[
<p>In my last blog post about bringing up a self-hosted Nextcloud setup, everything went well until it reached the SSL cert and configuration part. The instructions I found were all somehow missing some pieces or doing things a little bit differently than what I had expected, plus my own lack of in-depth understanding of SSL, I finally had my issues resolved with the help of these resources: <a rel="noreferrer noopener" href="https://stackoverflow.com/questions/46349459/chrome-neterr-cert-authority-invalid-error-on-self-signing-certificate-at-loca?rq=1" data-type="URL" data-id="https://stackoverflow.com/questions/46349459/chrome-neterr-cert-authority-invalid-error-on-self-signing-certificate-at-loca?rq=1" target="_blank">article 1</a>, <a rel="noreferrer noopener" href="https://alexanderzeitler.com/articles/Fixing-Chrome-missing_subjectAltName-selfsigned-cert-openssl/" data-type="URL" data-id="https://alexanderzeitler.com/articles/Fixing-Chrome-missing_subjectAltName-selfsigned-cert-openssl/" target="_blank">article 2</a>, <a rel="noreferrer noopener" href="https://superuser.com/questions/1631692/why-is-chrome-not-trusting-imported-self-signed-root-ca" data-type="URL" data-id="https://superuser.com/questions/1631692/why-is-chrome-not-trusting-imported-self-signed-root-ca" target="_blank">article 3</a>, <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=e8vMTlobW3c" data-type="URL" data-id="https://www.youtube.com/watch?v=e8vMTlobW3c" target="_blank">video</a>.</p>



<h2 class="wp-block-heading">Issues<strong>:</strong></h2>



<ul>
<li>SSL/HTTPS won&#8217;t go into effect even if I&#8217;ve enabled SSL in Apache, generated the certs, and configured the config files.</li>



<li>HTTPS goes into effect in Firefox but always said &#8220;Not Secure&#8221; or &#8220;Invalid&#8221; cert in Chrome.</li>



<li>Chrome errors: &#8220;NET::ERR_CERT_AUTHORITY_INVALID&#8221;, &#8220;NET::ERR_CERT_COMMON_NAME_INVALID&#8221;</li>
</ul>



<h2 class="wp-block-heading">Solutions:</h2>



<p>1. Originally, I followed this article to generate my certs, but the cert won&#8217;t get accepted by Chrome even if I&#8217;ve imported it into Trusted Root Certification Authorities store. The certificate generation procedures that worked are:</p>



<pre class="wp-block-code"><code># Generate a Certificate Authority (CA)

openssl genrsa -des3 -out nextcloudCA.key 2048
# A password needs to be created after this command is run.

openssl req -x509 -new -nodes -key nextcloudCA.key -sha256 -days 365 -out nextcloudCA.pem
# A series of information will be asked after this command is run. You can customize your own or just follow whatever is in the &#91;dn] section below.

openssl x509 -outform pem -in nextcloudCA.pem -out nextcloudCA.crt
# Generate a crt file for future import. The pem file can also be used for import.

# Prepare the v3.ext and config files.
# cert.csr.cnf file
&#91;req]
default_bits = 2048
prompt = no
default_md = sha256
distinguished_name = dn

&#91;dn]
C=Replace-with-Your-Info
ST=Replace-with-Your-Info
L=Replace-with-Your-Info
O=Replace-with-Your-Info
OU=Replace-with-Your-Info
emailAddress=Replace-with-Your-Info
CN=Replace-with-Your-Info

# v3.ext file
authorityKeyIdentifier=keyid,issuer
basicConstraints=CA:FALSE
keyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment
subjectAltName = @alt_names

&#91;alt_names]
DNS.1 = Replace-with-Your-Info-Or-Delete-Line
DNS.2 = Replace-with-Your-Info-Or-Delete-Line
DNS.3 = Replace-with-Your-Info-Or-Delete-Line
IP.1 = Replace-with-Your-Info-Or-Delete-Line
IP.2 = Replace-with-Your-Info-Or-Delete-Line

# Generate the domain name cert
openssl req -new -sha256 -nodes -out nextcloudDNCert.csr -newkey rsa:2048 -keyout nextcloudDNCert.key -config cert.csr.cnf

openssl x509 -req -in nextcloudDNCert.csr -CA nextcloudCA.crt -CAkey nextcloudCA.key -CAcreateserial -out nextcloudDNCert.crt -days 365 -sha256 -extfile v3.ext</code></pre>



<p>2. Put your cert files (<strong>nextcloudDNCert.crt</strong> and <strong>nextcloudDNCert.key</strong>) in the directories that&#8217;s suitable for your setup, and modify your SSL config file or the nextcloud.conf file to point to the cert files. Sample config files can be downloaded here: <a rel="noreferrer noopener" href="https://github.com/jameswsullivan/blog-file-share/blob/main/sample.nextcloud.conf" target="_blank">sample.nextcloud.conf</a> .</p>



<pre class="wp-block-code"><code># Under /etc/apache2/sites-available, modify nextcloud.conf .

SSLCertificateFile Your-Cert-File-Path
SSLCertificateKeyFile Your-Cert-Key-File-Path</code></pre>



<p>3. Restart Apache service</p>



<pre class="wp-block-code"><code>service apache2 restart</code></pre>



<p>4. Import <strong>nextcloudCA.crt</strong> into your Trusted Root Certification Authorities store, clear your browser&#8217;s cookies, restart the browser and access your Nextcloud server again, this time the HTTPS padlock should be solid grey, no &#8220;Not Secure&#8221; and other errors.</p>



<p>5. Explanation about the &#8220;NET::ERR_CERT_AUTHORITY_INVALID&#8221; and &#8220;NET::ERR_CERT_COMMON_NAME_INVALID&#8221; errors.</p>



<p>&#8220;NET::ERR_CERT_AUTHORITY_INVALID&#8221; is due to how the certs were generated, when using <a rel="noreferrer noopener" href="https://betterprogramming.pub/how-to-create-trusted-ssl-certificates-for-your-local-development-13fd5aad29c6" data-type="URL" data-id="https://betterprogramming.pub/how-to-create-trusted-ssl-certificates-for-your-local-development-13fd5aad29c6" target="_blank">this method</a> to generate, I always got the error, but after I switched to the method written in #1 and the certs were properly imported, this error was gone.</p>



<p>&#8220;NET::ERR_CERT_COMMON_NAME_INVALID&#8221; . Assuming you already put in the Common Name (which is your FQDN, e.g. nextcloud.mydomain.com) correctly when generating the certs and it still gave this error, check the @alt_names section above, make sure all the DNS.x and IP.x entries cover all your alt_name variants. Once I added stuff under the alt_names section correctly (for me it&#8217;s &#8220;localhost&#8221;, my server&#8217;s IP, and the &#8220;subdomain&#8221; URL I&#8217;d like to use in my own environment), the error was gone.</p>



<p>6. Other issues and thoughts that emerged during the troubleshooting process.</p>



<ol>
<li>Some mentioned that Chrome versions played a role in accepting self-signed certs. But my issues were resolved without dealing with Chrome versions.</li>



<li>I&#8217;ve seen posts mentioning the <code>chrome://flags/#allow-insecure-localhost</code> flag, but it didn&#8217;t apply to my scenario.</li>



<li>Some articles say that self-signed certs won&#8217;t be deemed secure and valid by browsers/OSs/Chrome, which is not true if the certs are generated imported and generated correctly.</li>
</ol>



<p>7. Security hardening &#8211; forcing HTTPS, Strict-Transport-Security, and URL redirections. See <a href="https://github.com/jameswsullivan/blog-file-share/blob/main/sample.nextcloud.conf" data-type="URL" data-id="https://drive.google.com/file/d/1QQRGrROpZhrnDc-ET8mDUfj2EjtHzAnK/view?usp=sharing" target="_blank" rel="noreferrer noopener">sample.nextcloud.conf</a> and its comments for details.</p>



<p>8. Apache&#8217;s SSL config files, which to use?</p>



<p>Assuming your installation is very similar to mine, you&#8217;d now have 3 files under /etc/apache2/sites-available : 000-default.conf, default-ssl.conf, and nextcloud.conf . </p>



<ul>
<li>000-default.conf is a template for you to start with, not a live file to use.</li>



<li>default-ssl.conf is the default Apache SSL config file.</li>



<li>nextcloud.conf is the config file for Nextcloud.</li>
</ul>



<p>You can choose either to use default-ssl.conf or nextcloud.conf, or a combination of both and use them for different purposes. I disabled default-ssl.conf by renaming it to default-ssl.conf.bak, and left nextcloud.conf active which has all my configs.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
